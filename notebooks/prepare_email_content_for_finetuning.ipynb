{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to process the results for finetuning of open LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea: if using the answers from OpenAI API a model could be finetuned to give even better results and could be used offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import openai\n",
    "from pandas import DataFrame, concat, read_csv, read_parquet,merge, ExcelWriter, read_excel\n",
    "import requests\n",
    "#from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "#from langchain.vectorstores import Chroma\n",
    "#from langchain.embeddings import OpenAIEmbeddings\n",
    "#from langchain.docstore.document import Document\n",
    "#from azure.data.tables import TableServiceClient, TableEntity\n",
    "#from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "import os\n",
    "from io import BytesIO\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "from numpy import array, array_split, float32, set_printoptions\n",
    "from multiprocessing import  Pool\n",
    "import tiktoken\n",
    "import re\n",
    "from itertools import islice\n",
    "import json\n",
    "import ast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTLOOK_CONTENT_CONNECTION_STRING = os.environ.get('OUTLOOK_CONTENT_CONNECTION_STRING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data from azure blob storage\n",
    "def get_data(file_name):\n",
    "    try:\n",
    "        # Create the BlobServiceClient object which will be used\n",
    "        blob_service_client = BlobServiceClient.from_connection_string(OUTLOOK_CONTENT_CONNECTION_STRING)\n",
    "\n",
    "        container_name = 'outlookcontent'\n",
    "        \n",
    "        # Create a blob client using the local file name as the name for the blob\n",
    "        blob_client = blob_service_client.get_blob_client(container=container_name, blob=file_name)\n",
    "        \n",
    "        #download blob\n",
    "        blob = blob_client.download_blob()\n",
    "        #convert blob to dataframe\n",
    "        df = read_parquet(BytesIO(blob.readall()))\n",
    "        \n",
    "                \n",
    "    except: \n",
    "        return \"error downloading data from blob storage\"\n",
    "\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = get_data('2023-07-12_outlook_summary_1000a.parquet')\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(997, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = get_data('2023-07-12_outlook_summary_1000b.parquet')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2897, 16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = concat([df1, df2])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index':'index_old'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2897 entries, 0 to 2896\n",
      "Data columns (total 17 columns):\n",
      " #   Column                   Non-Null Count  Dtype              \n",
      "---  ------                   --------------  -----              \n",
      " 0   index_old                2897 non-null   int64              \n",
      " 1   PartitionKey             2897 non-null   object             \n",
      " 2   RowKey                   2897 non-null   object             \n",
      " 3   subject                  2897 non-null   object             \n",
      " 4   content                  2897 non-null   object             \n",
      " 5   sender                   2897 non-null   object             \n",
      " 6   recipients               2897 non-null   object             \n",
      " 7   received_datetime        2897 non-null   datetime64[ns, UTC]\n",
      " 8   conversation_id          2897 non-null   object             \n",
      " 9   web_link                 2897 non-null   object             \n",
      " 10  content_cleaned          2897 non-null   object             \n",
      " 11  content_length           2897 non-null   int64              \n",
      " 12  content_tt_token_lenght  2897 non-null   int64              \n",
      " 13  content_processed        2897 non-null   object             \n",
      " 14  finish_reason            2897 non-null   object             \n",
      " 15  content_string           2897 non-null   object             \n",
      " 16  content_summary          2897 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(3), object(13)\n",
      "memory usage: 384.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#analyze df\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 17)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_error = df[df['finish_reason'] == 'Error']\n",
    "df_error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(543, 18)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['finish_reason_summary'] = df['content_summary'].apply(lambda x: x[\"choices\"][0][\"finish_reason\"])\n",
    "df_summmary_error = df[df['finish_reason_summary'] == 'Error']\n",
    "df_summmary_error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2354, 18)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['finish_reason_summary'] != 'Error']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#content_summary to content to string\n",
    "df.loc[:, 'summary'] = df['content_summary'].apply(lambda x: x[\"choices\"][0][\"message\"][\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['summary'] = df['summary'].str.replace(\"Max Mustermann, Erika Mustermann\", \"Unbekannt\").str.replace(\"Max Mustermann\", \"Unbekannt\").str.replace(\"Erika Mustermann\", \"Unbekannt\").str.replace(\"Max Mustermann, Erika Musterfrau\", \"Unbekannt\").str.replace(\"Max Mustermann, Erika Musterfrau\", \"Unbekannt\").str.replace(\"Max Mustermann, Erika Musterfrau\", \"Unbekannt\").str.replace(\"Max Mustermann, Erika Musterfrau\", \"Unbekannt\").str.replace(\"Max Mustermann, Erika Musterfrau\", \"Unbekannt\").str.replace(\"Max Mustermann, Erika Musterfrau\", \"Unbekannt\").str.replace(\"Max Mustermann, Erika Musterfrau\", \"Unbekannt\").str.replace(\"Max Mustermann, Erika Musterfrau\", \"Unbekannt\").str.replace(\"Max Mustermann, Erika Musterfrau\", \"Unbekannt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['summary'].str.contains('Mustermann').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df[['sender', 'content_cleaned', 'content_string', 'summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExcelWriter('../sample_files/content_summary.xlsx') as writer:\n",
    "    df_out.to_excel(writer, sheet_name='content_summary', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in = read_excel('../sample_files/content_summary.xlsx', sheet_name='content_summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in.rename(columns={'content_cleaned':'input', 'content_string': 'output'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in['instruction'] = \"\"\"Analysiere folgende Email-Unterhaltung, nach folgenden Kriterien: Sender, Gesendet, Betreff, Nachricht (nur Text, entferne Signaturen, Adressen, Bilder, Links, Disclaimer und Fussnoten), Typ (Frage, Antwort,Information, Aufforderung, Werbung...). Antwort in einer Liste. Einträge getrennt durch <br>. Format:\n",
    "<br>\n",
    "Typ: \n",
    "Sender: \n",
    "Gesendet: \n",
    "Subject:\n",
    "Nachricht:\n",
    "<br>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export columns instruction, input, output to jsonl file\n",
    "df_in[['instruction', 'input', 'output']].to_json('../sample_files/content_proccessed.jsonl', orient='records', lines=True, force_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop instruction column\n",
    "df_in.drop(columns=['instruction'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in['instruction'] = \"\"\"Erstelle eine Zusammenfassung der folgenden Email-Unterhaltung, inklusive der Personen, die daran beteiligt sind.\n",
    "                Beispiel:\n",
    "                Personen: \n",
    "                Zusammenfassung: In dieser Email-Unterhaltung geht es um..\n",
    "                 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in.rename(columns={'content_string':'input', 'summary': 'output'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export columns instruction, input, output to jsonl file\n",
    "df_in[['instruction', 'input', 'output']].to_json('../sample_files/content_summary.jsonl', orient='records', lines=True,force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add a dataset with instructions from HugginFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 1.63k/1.63k [00:00<00:00, 18.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/snipaid--instruct-snippet-mlsum-v2 to /home/bender/.cache/huggingface/datasets/snipaid___csv/snipaid--instruct-snippet-mlsum-v2-b5b17d046b68c730/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 10.8M/10.8M [00:00<00:00, 12.7MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:01<00:00,  1.93s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 2344.50it/s]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/bender/.cache/huggingface/datasets/snipaid___csv/snipaid--instruct-snippet-mlsum-v2-b5b17d046b68c730/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 405.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "data = datasets.load_dataset('snipaid/instruct-snippet-mlsum-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_parquet('../sample_files/csv-train.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>title</td>\n",
       "      <td>Welcher Titel würde den Kern des Artikels am b...</td>\n",
       "      <td>Die Cadillac des Jahrgangs 2005 haben nicht me...</td>\n",
       "      <td>Fahrbericht: Cadillac STS 4.6 V8 - Habt Acht!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>title</td>\n",
       "      <td>Gib diesem Text eine ansprechende Überschrift.</td>\n",
       "      <td>Motorisierte Taxis gibt es schon fast so lange...</td>\n",
       "      <td>London Taxis - Black Cabs auf Tour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>title</td>\n",
       "      <td>Welche Schlagzeile würde die Aufmerksamkeit de...</td>\n",
       "      <td>GS, das war einmal: Hightech kompakt verpackt ...</td>\n",
       "      <td>Citroën C5 - Zeit-Maschine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>title</td>\n",
       "      <td>Finde eine Überschrift.</td>\n",
       "      <td>Zoe ist ein altgriechisches Wort und bedeutet ...</td>\n",
       "      <td>Elektroauto Renault Zoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>title</td>\n",
       "      <td>Finde eine passende Überschrift für den folgen...</td>\n",
       "      <td>\"Zuletzt gesichtet vor Cape Flattery.\" So lako...</td>\n",
       "      <td>Gefährliche Wasserstraßen - Hochspannung am Pu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                        instruction  \\\n",
       "0  title  Welcher Titel würde den Kern des Artikels am b...   \n",
       "1  title     Gib diesem Text eine ansprechende Überschrift.   \n",
       "2  title  Welche Schlagzeile würde die Aufmerksamkeit de...   \n",
       "3  title                            Finde eine Überschrift.   \n",
       "4  title  Finde eine passende Überschrift für den folgen...   \n",
       "\n",
       "                                               input  \\\n",
       "0  Die Cadillac des Jahrgangs 2005 haben nicht me...   \n",
       "1  Motorisierte Taxis gibt es schon fast so lange...   \n",
       "2  GS, das war einmal: Hightech kompakt verpackt ...   \n",
       "3  Zoe ist ein altgriechisches Wort und bedeutet ...   \n",
       "4  \"Zuletzt gesichtet vor Cape Flattery.\" So lako...   \n",
       "\n",
       "                                              output  \n",
       "0      Fahrbericht: Cadillac STS 4.6 V8 - Habt Acht!  \n",
       "1                 London Taxis - Black Cabs auf Tour  \n",
       "2                         Citroën C5 - Zeit-Maschine  \n",
       "3                            Elektroauto Renault Zoe  \n",
       "4  Gefährliche Wasserstraßen - Hochspannung am Pu...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data to jsonl file\n",
    "train_data[['instruction', 'input', 'output']].to_json('../sample_files/instruct_snippet_mlsunV2.jsonl', orient='records', lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to upload data to azure blob storage\n",
    "def upload_data(df):\n",
    "    try:\n",
    "        #Save to Azure Blob Storage\n",
    "        # Create the BlobServiceClient object which will be used\n",
    "        blob_service_client = BlobServiceClient.from_connection_string(OUTLOOK_CONTENT_CONNECTION_STRING)\n",
    "\n",
    "        container_name = 'outlookcontent'\n",
    "        #get today's date\n",
    "        today = date.today().strftime('%Y-%m-%d')\n",
    "        # Create a blob client using the local file name as the name for the blob\n",
    "        file_name = today + \"_outlook_data.parquet\"\n",
    "        blob_client = blob_service_client.get_blob_client(container=container_name, blob=file_name)\n",
    "        \n",
    "        # save dataframe to csv\n",
    "        #csv_file = df.to_csv(index=False)\n",
    "\n",
    "        parquet_file = BytesIO()\n",
    "        df.to_parquet(parquet_file,  engine='pyarrow')\n",
    "        parquet_file.seek(0)  # change the stream position back to the beginning after writing\n",
    "        response = blob_client.upload_blob(data=parquet_file, overwrite=True)\n",
    "\n",
    "        \n",
    "    except:\n",
    "        print(\"error uploading data to blob storage\")\n",
    "    else:\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_data(df_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_printoptions(linewidth=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal = df._to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal.to_excel(\"outlook1_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = df_normal.content_processed.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[140:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal.to_csv(\"outlook1_data2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[140:150].to_csv(\"test.csv\",sep=';', encoding='utf-8', quotechar='\"', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[140][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[142][\"content_cleaned\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[11][\"content_cleaned\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iloc[0][\"content_processed\"][\"choices\"][0][\"message\"]['content'].json.loads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Analysiere folgende Email-Unterhaltung, getrennt durch dreifache Anführungsstrich, nach folgenden Kriterien:\n",
    "- Sender\n",
    "- Gesendet\n",
    "- Betreff\n",
    "- Nachricht (nur Text, keine Signaturen oder Fussnoten)\n",
    "- Typ (Frage, Antwort, Information, Aufforderung, Werbung...)\n",
    "\n",
    "Antwort als JSON-Objekte in einer Liste. Liste sortiert nach Datum Gesendet, älteste zuerst. JSON-Objekte mit den Kriterien als Keys und den entsprechenden Werten.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens_from_string(prompt, \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def pretty_print(text):\n",
    "    return display( HTML( text.replace(\"\\\\r\",\"<br>\") ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(df.content_cleaned[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.content_cleaned[1305]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_string_by_email(text):\n",
    "    # Use a regex to split the string at each 'Von:' followed by an email (up to the next '<')\n",
    "    return re.split(r'Von:.*?<', text)\n",
    "\n",
    "example_string = df.iloc[11][\"content_cleaned\"]  # Your string here\n",
    "\n",
    "split_result = split_string_by_email(example_string)\n",
    "\n",
    "for i, part in enumerate(split_result):\n",
    "    print(f\"Part {i}:\")\n",
    "    print(part)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_download.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean json string to be able to convert to json\n",
    "df_download[\"content_processed\"] = df_download[\"content_processed\"].apply(lambda x: x.replace(\"\\'\", '\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert string to json\n",
    "df1[\"content_processed_content\"] = df1[\"content_processed\"].apply(lambda x: x[\"choices\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "ast.literal_eval(df1.iloc[1][\"content_processed_content\"][\"choices\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iloc[1][\"content_processed_content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"How is the regex for multiple new lines?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    temperature=0, # this is the degree of randomness of the model's output\n",
    "    max_tokens=4000, # this is the maximum number of tokens that the model will generate\n",
    "    n=1, # this is the number of samples to return\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.to_csv(\"outlook1_data3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_save = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_save2 = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace empty lists in content_processed with empty dict\n",
    "df_save[\"content_processed\"] = df_save[\"content_processed\"].apply(lambda x: {} if x == [] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_save.to_parquet(\"outlook1_data.parquet\", engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
