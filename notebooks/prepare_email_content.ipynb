{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to test the email content processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### includs test with Modin on Dask as distributed compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from pandas import DataFrame, concat, read_csv, read_parquet    \n",
    "import requests\n",
    "#from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "#from langchain.vectorstores import Chroma\n",
    "#from langchain.embeddings import OpenAIEmbeddings\n",
    "#from langchain.docstore.document import Document\n",
    "from azure.data.tables import TableServiceClient, TableEntity\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "import os\n",
    "from io import BytesIO\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "from numpy import array, array_split, float32, set_printoptions\n",
    "from multiprocessing import  Pool\n",
    "import tiktoken\n",
    "import re\n",
    "from itertools import islice\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started cluster at http://127.0.0.1:8787/status\n"
     ]
    }
   ],
   "source": [
    "import modin\n",
    "os.environ[\"MODIN_CPUS\"] = \"24\"\n",
    "import modin.pandas as mpd\n",
    "from distributed import Client\n",
    "# global variable\n",
    "DASK_RUNNING = False\n",
    "\n",
    "os.environ[\"MODIN_ENGINE\"] = \"dask\"  # Modin will use Dask\n",
    "if not DASK_RUNNING:\n",
    "        from dask.distributed import Client, LocalCluster\n",
    "        cluster = LocalCluster()  # Launches a scheduler and workers locally\n",
    "        client = Client(cluster)  # Connect to distributed cluster and override default\n",
    "        print(f\"Started cluster at {cluster.dashboard_link}\")\n",
    "        DASK_RUNNING = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "import modin\n",
    "print(modin.config.NPartitions.get())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTLOOK_CONTENT_CONNECTION_STRING = os.environ.get('OUTLOOK_CONTENT_CONNECTION_STRING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#progress bar for pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "encoding.encode(\"tiktoken is great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from azure storage table and create data frame\n",
    "\n",
    "def load_data():\n",
    "    # Create the TableServiceClient object which will be used to create a container client\n",
    "    connect_str = OUTLOOK_CONTENT_CONNECTION_STRING\n",
    "    table_service = TableServiceClient.from_connection_string(connect_str)\n",
    "    table_name = \"outlooktest\"\n",
    "    table_client = table_service.get_table_client(table_name) \n",
    "    documents = []\n",
    "    for entity in table_client.list_entities():\n",
    "        documents.append(entity)\n",
    "    #df =DataFrame(documents)\n",
    "    df = mpd.DataFrame(documents)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_content(row):\n",
    "    content = row['content']\n",
    "    content = content.replace(\"\\r\\n\", \"\\r\")\n",
    "    content = re.sub(r\"\\r+\", \"\\r\", content)\n",
    "    content = re.sub(r\"\\[(.*?)\\]\", \" \", content)\n",
    "    \n",
    "\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to break up text into chunks \n",
    "def batched(iterable, n):\n",
    "    \"\"\"Batch data into tuples of length n. The last batch may be shorter.\"\"\"\n",
    "    # batched('ABCDEFG', 3) --> ABC DEF G\n",
    "    if n < 1:\n",
    "        raise ValueError('n must be at least one')\n",
    "    it = iter(iterable)\n",
    "    while (batch := tuple(islice(it, n))):\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function that encodes a string into tokens and then breaks it up into chunks\n",
    "def chunked_tokens(text, encoding_name, chunk_length):\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    tokens = encoding.encode(text)\n",
    "    chunks_iterator = batched(tokens, chunk_length)\n",
    "    yield from chunks_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unction to count tokens\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func, n_cores=8):\n",
    "    df_split = array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO - SPLITS LONG CONTENTS INTO CHUNKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funciton to query chatgpt with content, ask for classification and return response\n",
    "def get_completion(row):\n",
    "    prompt = f\"\"\"\n",
    "                Analysiere folgende Email-Unterhaltung, getrennt durch <>, nach folgenden Kriterien:\n",
    "                - Sender\n",
    "                - Gesendet\n",
    "                - Betreff\n",
    "                - Nachricht (nur Text, keine Signaturen, Adressen, Bilder, Links, Disclaimer oder Fussnoten)\n",
    "                - Typ (Frage, Antwort, Information, Aufforderung, Werbung...)\n",
    "\n",
    "                Antwort als JSON-Objekte in einer Liste. Liste sortiert nach Datum Gesendet, Ã¤lteste zuerst. \n",
    "                Beispiel:\n",
    "                [{{\"Sender\": \"Max Mustermann\", \"Gesendet\": \"2021-01-01\", \"Betreff\": \"Test\", \"Nachricht\": \"Hallo Welt\", \"Typ\": \"Frage\"}}]\n",
    "                <{row['content']}>\n",
    "                \"\"\"\n",
    "    try:\n",
    "        if row['content_token_lenght'] < 2000:\n",
    "            model = \"gpt-3.5-turbo\"\n",
    "            max_tokens=3800 - row['content_token_lenght']\n",
    "        else:\n",
    "            model = \"gpt-3.5-turbo-16k\"\n",
    "            max_tokens=15500 - row['content_token_lenght']\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0, # this is the degree of randomness of the model's output\n",
    "            max_tokens=max_tokens, # this is the maximum number of tokens that the model will generate\n",
    "            n=1, # this is the number of samples to return\n",
    "        )\n",
    "        return response\n",
    "    except:\n",
    "        response = {\"choices\": [{\"text\": \"Error\"}]}\n",
    "        return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'list'> object. This may take some time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1836, 10)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = load_data()\n",
    "df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1821, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_list_PartitionKey = [\"noreply@emeaemail.teams.microsoft.com\", 'Ambassador@mc.ihg.com', 'microsoft-noreply@microsoft.com']\n",
    "df = df[~df['PartitionKey'].isin(drop_list_PartitionKey)]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modin.pandas as mpd\n",
    "#sample = mpd.DataFrame(get_sample())\n",
    "df['content_cleaned'] = df.apply(clean_content, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content_cleaned'] = df.apply(clean_content, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27565"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get row with longest content\n",
    "df[\"content_length\"] = df[\"content_cleaned\"].apply(lambda x: len(x))\n",
    "df[\"content_length\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get index of row with longest content\n",
    "df[\"content_length\"].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1305][\"content_cleaned\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8882"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count tokens in content\n",
    "df[\"content_token_lenght\"] = df[\"content\"].apply(lambda x: num_tokens_from_string(x, \"cl100k_base\"))\n",
    "df[\"content_token_lenght\"].max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"content_token_lenght\"].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iloc[0][\"content_token_lenght\"].dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_parallel(df):\n",
    "    df['content_processed'] = df.apply(get_completion, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = parallelize_dataframe(df1, apply_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"content_processed\"]= df.apply(get_completion, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace empty lists in content_processed with empty dict\n",
    "df[\"content_processed\"] = df[\"content_processed\"].apply(lambda x: {} if x == [] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal = df._to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to upload data to azure blob storage\n",
    "def upload_data(df):\n",
    "    try:\n",
    "        #Save to Azure Blob Storage\n",
    "        # Create the BlobServiceClient object which will be used\n",
    "        blob_service_client = BlobServiceClient.from_connection_string(OUTLOOK_CONTENT_CONNECTION_STRING)\n",
    "\n",
    "        container_name = 'outlookcontent'\n",
    "        #get today's date\n",
    "        today = date.today().strftime('%Y-%m-%d')\n",
    "        # Create a blob client using the local file name as the name for the blob\n",
    "        file_name = today + \"_outlook_data.parquet\"\n",
    "        blob_client = blob_service_client.get_blob_client(container=container_name, blob=file_name)\n",
    "        \n",
    "        # save dataframe to csv\n",
    "        #csv_file = df.to_csv(index=False)\n",
    "\n",
    "        parquet_file = BytesIO()\n",
    "        df.to_parquet(parquet_file,  engine='pyarrow')\n",
    "        parquet_file.seek(0)  # change the stream position back to the beginning after writing\n",
    "        response = blob_client.upload_blob(data=parquet_file, overwrite=True)\n",
    "\n",
    "        \n",
    "    except:\n",
    "        print(\"error uploading data to blob storage\")\n",
    "    else:\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_data(df_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_printoptions(linewidth=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal = df._to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal.to_excel(\"outlook1_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = df_normal.content_processed.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[140:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal.to_csv(\"outlook1_data2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `to_csv` is not currently supported by PandasOnDask, defaulting to pandas implementation.\n"
     ]
    }
   ],
   "source": [
    "df.iloc[140:150].to_csv(\"test.csv\",sep=';', encoding='utf-8', quotechar='\"', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[140][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[142][\"content_cleaned\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[11][\"content_cleaned\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iloc[0][\"content_processed\"][\"choices\"][0][\"message\"]['content'].json.loads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Analysiere folgende Email-Unterhaltung, getrennt durch dreifache AnfÃ¼hrungsstrich, nach folgenden Kriterien:\n",
    "- Sender\n",
    "- Gesendet\n",
    "- Betreff\n",
    "- Nachricht (nur Text, keine Signaturen oder Fussnoten)\n",
    "- Typ (Frage, Antwort, Information, Aufforderung, Werbung...)\n",
    "\n",
    "Antwort als JSON-Objekte in einer Liste. Liste sortiert nach Datum Gesendet, Ã¤lteste zuerst. JSON-Objekte mit den Kriterien als Keys und den entsprechenden Werten.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens_from_string(prompt, \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def pretty_print(text):\n",
    "    return display( HTML( text.replace(\"\\\\r\",\"<br>\") ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(df.content_cleaned[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.content_cleaned[1305]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_string_by_email(text):\n",
    "    # Use a regex to split the string at each 'Von:' followed by an email (up to the next '<')\n",
    "    return re.split(r'Von:.*?<', text)\n",
    "\n",
    "example_string = df.iloc[11][\"content_cleaned\"]  # Your string here\n",
    "\n",
    "split_result = split_string_by_email(example_string)\n",
    "\n",
    "for i, part in enumerate(split_result):\n",
    "    print(f\"Part {i}:\")\n",
    "    print(part)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1821, 14)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_download.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean json string to be able to convert to json\n",
    "df_download[\"content_processed\"] = df_download[\"content_processed\"].apply(lambda x: x.replace(\"\\'\", '\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert string to json\n",
    "df1[\"content_processed_content\"] = df1[\"content_processed\"].apply(lambda x: x[\"choices\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "ast.literal_eval(df1.iloc[1][\"content_processed_content\"][\"choices\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iloc[1][\"content_processed_content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"How is the regex for multiple new lines?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    temperature=0, # this is the degree of randomness of the model's output\n",
    "    max_tokens=4000, # this is the maximum number of tokens that the model will generate\n",
    "    n=1, # this is the number of samples to return\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'list'> object. This may take some time.\n"
     ]
    }
   ],
   "source": [
    "df_temp = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `to_csv` is not currently supported by PandasOnDask, defaulting to pandas implementation.\n"
     ]
    }
   ],
   "source": [
    "df_temp.to_csv(\"outlook1_data3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_save = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_save2 = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace empty lists in content_processed with empty dict\n",
    "df_save[\"content_processed\"] = df_save[\"content_processed\"].apply(lambda x: {} if x == [] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_save.to_parquet(\"outlook1_data.parquet\", engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
